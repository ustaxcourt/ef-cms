version: 2.1
orbs:
  git-shallow-clone: guitarrapc/git-shallow-clone@2.4.0

commands:
  npm-and-cypress-install:
    steps:
      - restore_cache:
          keys:
            - v20-npm-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
      - restore_cache:
          keys:
            - v20-cypress-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: |
            if [ ! -d node_modules ]; then
              npm ci
            else
              echo package.json and package-lock.json are unchanged. Using cached node_modules folder.
            fi
      - run:
          name: Install Cypress dependency
          command: |
            if [ ! -d ~/.cache/Cypress ]; then
              echo Installing Cypress
              ./node_modules/.bin/cypress install
            else
              echo Found cached Cypress version. Using cached Cypress folder.
            fi
      - run:
          name: Reset package-lock
          command: 'git checkout -- package-lock.json'
      - save_cache:
          key: v20-npm-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - save_cache:
          key: v20-cypress-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
          paths:
            - ~/.cache/Cypress
  npm-install:
    steps:
      - restore_cache:
          keys:
            - v20-npm-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: |
            if [ ! -d node_modules ]; then
              npm ci
            else
              echo package.json and package-lock.json are unchanged. Using cached node_modules folder.
            fi
      - run:
          name: Reset package-lock
          command: 'git checkout -- package-lock.json'
      - save_cache:
          key: v20-npm-{{ checksum "package.json" }}-{{ checksum "package-lock.json" }}
          paths:
            - node_modules

jobs:
  build-client-integration:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    parallelism: 8
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Create web-client Artifacts Directory
          command: mkdir /tmp/web-client/
      - run:
          name: Web Client - Integration Test
          command: |
            CI=true \
            TEMP_DOCUMENTS_BUCKET_NAME=noop-temp-documents-local-us-east-1 \
            QUARANTINE_BUCKET_NAME=noop-quarantine-local-us-east-1 \
            DOCUMENTS_BUCKET_NAME=noop-documents-local-us-east-1 \
            S3_ENDPOINT=http://localhost:9000 \
            SKIP_CACHE_INVALIDATION=true \
            AWS_ACCESS_KEY_ID=S3RVER \
            AWS_SECRET_ACCESS_KEY=S3RVER \
            npm run start:api:ci > /tmp/web-client/server-output.txt &
            URL=http://localhost:4000/api/swagger ./wait-until.sh
            URL=http://localhost:9200 ./wait-until.sh
            URL=http://localhost:9000/ ./wait-until.sh
            URL=http://localhost:8000/shell ./wait-until.sh
            sleep 20 # figure out why we need to sleep here since we wait above ^
            export TESTFILES=$(circleci tests glob "web-client/integration-tests/*.test.js" "web-client/integration-tests-public/*.test.js" | circleci tests split --split-by=timings)
            npm run test:client:integration:ci
      - store_artifacts:
          path: /tmp/web-client
      - persist_to_workspace:
          root: ~/
          paths:
            - project/web-client
            - project/web-client/coverage-integration-*

  verify-pdfs:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Verify PDFs
          command: |
            npm run test:pdf-output
            node image-compare-pdfs.js

  e2e-pa11y:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Create Pa11y Artifacts Directory
          command: mkdir /tmp/pa11y
      - run:
          name: Pa11y
          environment:
            CI: true
            SKIP_CACHE_INVALIDATION: true
            TEMP_DOCUMENTS_BUCKET_NAME: noop-temp-documents-local-us-east-1
            QUARANTINE_BUCKET_NAME: noop-quarantine-local-us-east-1
            DOCUMENTS_BUCKET_NAME: noop-documents-local-us-east-1
            S3_ENDPOINT: http://localhost:9000
            MASTER_DYNAMODB_ENDPOINT: http://localhost:8000
            AWS_ACCESS_KEY_ID: S3RVER
            AWS_SECRET_ACCESS_KEY: S3RVER
          command: |
            npx --no-install run-p start:api:ci start:client:ci >> /tmp/pa11y/pa11y-server.txt &
            URL=http://localhost:1234 ./wait-until.sh
            URL=http://localhost:4000/api/swagger ./wait-until.sh
            URL=http://localhost:8000/shell ./wait-until.sh
            URL=http://localhost:9200/ CHECK_CODE=200 ./wait-until.sh
            sleep 10
            npm run test:pa11y:1 --node-flags --max-old-space-size=1024
            npm run test:pa11y:2 --node-flags --max-old-space-size=1024
            npm run test:pa11y:3 --node-flags --max-old-space-size=1024
            npm run test:pa11y:4 --node-flags --max-old-space-size=1024
      - store_artifacts:
          path: /root/project/web-client/pa11y/pa11y-screenshots
      - store_artifacts:
          path: /tmp/pa11y

  e2e-pa11y-public:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Create Pa11y Artifacts Directory
          command: mkdir /tmp/pa11y
      - run:
          name: Pa11y
          environment:
            CI: true
            SKIP_CACHE_INVALIDATION: true
            TEMP_DOCUMENTS_BUCKET_NAME: noop-temp-documents-local-us-east-1
            QUARANTINE_BUCKET_NAME: noop-quarantine-local-us-east-1
            DOCUMENTS_BUCKET_NAME: noop-documents-local-us-east-1
            S3_ENDPOINT: http://localhost:9000
            MASTER_DYNAMODB_ENDPOINT: http://localhost:8000
            AWS_ACCESS_KEY_ID: S3RVER
            AWS_SECRET_ACCESS_KEY: S3RVER
          command: |
            npx --no-install run-p start:api:ci start:public:ci >> /tmp/pa11y/pa11y-server.txt &
            ./wait-until-services.sh
            URL=http://localhost:5000/ ./wait-until.sh
            sleep 10
            npm run test:pa11y:public --node-flags --max-old-space-size=1536
      - store_artifacts:
          path: /root/project/web-client/pa11y/pa11y-screenshots
      - store_artifacts:
          path: /tmp/pa11y

  e2e-pa11y-public-search:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Create Pa11y Artifacts Directory
          command: mkdir /tmp/pa11y
      - run:
          name: Pa11y
          environment:
            CI: true
            SKIP_CACHE_INVALIDATION: true
            TEMP_DOCUMENTS_BUCKET_NAME: noop-temp-documents-local-us-east-1
            QUARANTINE_BUCKET_NAME: noop-quarantine-local-us-east-1
            DOCUMENTS_BUCKET_NAME: noop-documents-local-us-east-1
            S3_ENDPOINT: http://localhost:9000
            MASTER_DYNAMODB_ENDPOINT: http://localhost:8000
            AWS_ACCESS_KEY_ID: S3RVER
            AWS_SECRET_ACCESS_KEY: S3RVER
          command: |
            npx --no-install run-p start:api:ci start:public:ci >> /tmp/pa11y/pa11y-server.txt &
            ./wait-until-services.sh
            URL=http://localhost:5000/ ./wait-until.sh
            sleep 10
            npm run test:pa11y:public-search --node-flags --max-old-space-size=1536
      - store_artifacts:
          path: /root/project/web-client/pa11y/pa11y-screenshots
      - store_artifacts:
          path: /tmp/pa11y

  e2e-cypress:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-and-cypress-install
      - run:
          name: Create Cypress Artifacts Directory
          command: mkdir /tmp/cypress
      - run:
          name: Cypress
          environment:
            CI: true
            SKIP_CACHE_INVALIDATION: true
            TEMP_DOCUMENTS_BUCKET_NAME: noop-temp-documents-local-us-east-1
            QUARANTINE_BUCKET_NAME: noop-quarantine-local-us-east-1
            DOCUMENTS_BUCKET_NAME: noop-documents-local-us-east-1
            S3_ENDPOINT: http://localhost:9000
            MASTER_DYNAMODB_ENDPOINT: http://localhost:8000
            AWS_ACCESS_KEY_ID: S3RVER
            AWS_SECRET_ACCESS_KEY: S3RVER
          command: |
            npx --no-install run-p start:api:ci start:client:ci start:public:ci > /tmp/cypress/cypress-output.txt &
            ./wait-until-services.sh
            URL=http://localhost:4000/api/swagger ./wait-until.sh
            sleep 5
            npm run cypress:integration
      - store_artifacts:
          path: /root/project/cypress/videos/
      - store_artifacts:
          path: /tmp/cypress

  e2e-cypress-smoketests-local:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-and-cypress-install
      - run:
          name: Create Cypress Artifacts Directory
          command: mkdir /tmp/cypress
      - run:
          name: Cypress
          environment:
            CI: true
            SKIP_CACHE_INVALIDATION: true
            TEMP_DOCUMENTS_BUCKET_NAME: noop-temp-documents-local-us-east-1
            QUARANTINE_BUCKET_NAME: noop-quarantine-local-us-east-1
            DOCUMENTS_BUCKET_NAME: noop-documents-local-us-east-1
            S3_ENDPOINT: http://localhost:9000
            MASTER_DYNAMODB_ENDPOINT: http://localhost:8000
            AWS_ACCESS_KEY_ID: S3RVER
            AWS_SECRET_ACCESS_KEY: S3RVER
          command: |
            CYPRESS_VERSION=`./node_modules/.bin/cypress --version | awk -F' ' '{print $4; exit}'`
            if [ ! -e "/root/.cache/Cypress/${CYPRESS_VERSION}/Cypress/Cypress" ]; then
              ./node_modules/.bin/cypress install
            fi
            npx --no-install run-p start:api:ci start:client:ci > /tmp/cypress/cypress-output.txt &
            ./wait-until-services.sh
            URL=http://localhost:4000/api/swagger ./wait-until.sh
            sleep 5
            npm run cypress:smoketests:local
      - store_artifacts:
          path: /root/project/cypress-smoketests/videos/
      - store_artifacts:
          path: /tmp/cypress

  e2e-cypress-public:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
      - image: amazon/dynamodb-local
        command: ['-jar', 'DynamoDBLocal.jar', '-inMemory']
        environment:
          discovery.type: single-node
          JAVA_OPTS: '-Xms512m -Xmx512m'
      - image: elastic/elasticsearch:7.10.2
        environment:
          discovery.type: single-node
          ES_JAVA_OPTS: '-Xms512m -Xmx512m'
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-and-cypress-install
      - run:
          name: Create Cypress Artifacts Directory
          command: mkdir /tmp/cypress
      - run:
          name: Cypress
          environment:
            CI: true
            SKIP_CACHE_INVALIDATION: true
            TEMP_DOCUMENTS_BUCKET_NAME: noop-temp-documents-local-us-east-1
            QUARANTINE_BUCKET_NAME: noop-quarantine-local-us-east-1
            DOCUMENTS_BUCKET_NAME: noop-documents-local-us-east-1
            S3_ENDPOINT: http://localhost:9000
            MASTER_DYNAMODB_ENDPOINT: http://localhost:8000
            AWS_ACCESS_KEY_ID: S3RVER
            AWS_SECRET_ACCESS_KEY: S3RVER
            CHECK_DEPLOY_DATE_INTERVAL: 5000
          command: |
            CYPRESS_VERSION=`./node_modules/.bin/cypress --version | awk -F' ' '{print $4; exit}'`
            if [ ! -e "/root/.cache/Cypress/${CYPRESS_VERSION}/Cypress/Cypress" ]; then
              ./node_modules/.bin/cypress install
            fi
            npx --no-install run-p start:api:ci start:public:ci > /tmp/cypress/cypress-output.txt &
            ./wait-until-services.sh
            URL=http://localhost:4000/api/swagger ./wait-until.sh
            sleep 5
            npm run cypress:integration:public
      - store_artifacts:
          path: /root/project/cypress-integration/videos/public
      - store_artifacts:
          path: /tmp/cypress

  deploy:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: xlarge # this should be temporary until we improve memory usage of 'Deploy - Web Client - S3'
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
            echo "export CURRENT_COLOR=$(./scripts/dynamo/get-current-color.sh $ENV)" >> $BASH_ENV
      - run:
          name: Build Docker Image
          command: |
            cd web-api/runtimes/puppeteer && ./build.sh && cd ../../..
      - run:
          name: Setup Blue Green Migration If Needed
          command: |
            ./setup-for-blue-green-migration.sh
      - run:
          name: Setup Reindex If Needed
          command: |
            ./setup-for-reindex.sh
      - run:
          name: Setup Migrate Flag
          command: echo "export MIGRATE_FLAG=$(./scripts/dynamo/get-migrate-flag.sh $ENV)" >> $BASH_ENV
      - run:
          name: Setup Reindex Flag
          command: echo "export REINDEX_FLAG=$(./scripts/dynamo/get-reindex-flag.sh $ENV)" >> $BASH_ENV
      - run:
          name: Setup Destination Table Var
          command: echo "export DESTINATION_TABLE=$(./scripts/dynamo/get-destination-table.sh $ENV)" >> $BASH_ENV
      - run:
          no_output_timeout: 20m
          name: 'Deploy - Web API - Terraform'
          command: |
            cd web-api/terraform/main && ../bin/deploy-app.sh $ENV
      - run:
          no_output_timeout: 20m
          name: 'Deploy - Web Client - Terraform'
          command: |
            cd web-client/terraform/main && ../bin/deploy-app.sh $ENV
      - run:
          name: Setup Elasticsearch Index Settings
          command: |
            ./web-api/setup-elasticsearch-index.sh $ENV
      - run:
          name: Admin User Setup
          command: |
            if [ "${CIRCLE_BRANCH}" != "prod" ]; then
              node shared/admin-tools/user/setup-admin.js
            else
              echo "skipping…"
            fi
      - run:
          name: Test Users Setup
          command: |
            if [ "${CIRCLE_BRANCH}" != "prod" ]; then
              ./shared/admin-tools/user/setup-test-users.sh $ENV
            else
              echo "skipping…"
            fi
      - run:
          name: Setup Judge Users File Var
          command: |
            if [ "${CIRCLE_BRANCH}" != "prod" ] && [ "${CIRCLE_BRANCH}" != "test" ] && [ "${CIRCLE_BRANCH}" != "migration" ]; then
              echo "export FILE_NAME=./scripts/data-import/judge/judge_users.csv" >> $BASH_ENV
            else
              echo "skipping…"
            fi
      - run:
          name: Judge Users Setup
          command: |
            if [ "${CIRCLE_BRANCH}" != "prod" ] && [ "${CIRCLE_BRANCH}" != "test" ] && [ "${CIRCLE_BRANCH}" != "migration" ]; then
              ./scripts/data-import/judge/bulk-import-judge-users.sh
            else
              echo "skipping…"
            fi
      - run:
          name: 'Deploy - Web Client - S3'
          command: |
            ./web-client/deploy-ui.sh
      - run:
          name: 'Deploy - Public Web Client - S3'
          command: |
            ./web-client/deploy-public.sh
      - run:
          name: 'Deploy - Web API - Cognito Customize'
          command: |
            cd web-api && ./setup-cognito-ui.sh $ENV
      - run:
          name: 'Deploy - Web API - Smoke Tests - us-east-1'
          command: |
            if [ "${CIRCLE_BRANCH}" == "develop" ] || [ "${CIRCLE_BRANCH}" == "experimental1" ] || [ "${CIRCLE_BRANCH}" == "experimental2" ] || [ "${CIRCLE_BRANCH}" == "experimental3" ] || [ "${CIRCLE_BRANCH}" == "experimental4" ] || [ "${CIRCLE_BRANCH}" == "experimental5" ] || [ "${CIRCLE_BRANCH}" == "staging" ] || [ "${CIRCLE_BRANCH}" == "irs" ]; then
              cd web-api && node smoke-tests.js $ENV us-east-1 ${DEPLOYING_COLOR} ${DEFAULT_ACCOUNT_PASS}
            else
              echo "skipping…"
            fi
      - run:
          name: 'Deploy - Web API - Smoke Tests - us-west-1'
          command: |
            if [ "${CIRCLE_BRANCH}" == "develop" ] || [ "${CIRCLE_BRANCH}" == "experimental1" ] || [ "${CIRCLE_BRANCH}" == "experimental2" ] || [ "${CIRCLE_BRANCH}" == "experimental3" ] || [ "${CIRCLE_BRANCH}" == "experimental4" ] || [ "${CIRCLE_BRANCH}" == "experimental5" ] || [ "${CIRCLE_BRANCH}" == "staging" ] || [ "${CIRCLE_BRANCH}" == "irs" ]; then
              cd web-api && node smoke-tests.js $ENV us-west-1 ${DEPLOYING_COLOR} ${DEFAULT_ACCOUNT_PASS}
            else
              echo "skipping…"
            fi
      - run:
          name: 'Deploy - Authorizer Smoke Tests'
          command: |
            npm run verify-authorizers -- $ENV
      - run:
          name: 'Deploy - Verify Private S3 Buckets'
          command: |
            npm run verify-private-s3-buckets -- $ENV
      - run:
          name: 'Deploy - Verify Private Elasticsearch'
          command: |
            npm run verify-private-elasticsearch -- $ENV
      - run:
          name: 'Deploy - Verify Cognito Lambda Triggers'
          command: |
            npm run verify-cognito-lambda-triggers -- $ENV
      - store_artifacts:
          path: /home/app/cypress-smoketests/videos/
      - run:
          name: 'Deploy - Pending Color Switch'
          command: npm run pending-color-switch

  reindex:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export REINDEX_FLAG=$(./scripts/dynamo/get-reindex-flag.sh $ENV)" >> $BASH_ENV
            echo "export MIGRATE_FLAG=$(./scripts/dynamo/get-migrate-flag.sh $ENV)" >> $BASH_ENV
            if [ "$REINDEX_FLAG" == "true" ] && [ "$MIGRATE_FLAG" == "false" ]; then
              cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
              source $BASH_ENV
              echo "export DESTINATION_TABLE=$(./scripts/dynamo/get-destination-table.sh $ENV)" >> $BASH_ENV
            fi
      - run:
          name: Enable Check Reindex Status Cron
          command: |
            if [ "$REINDEX_FLAG" == "true" ] && [ "$MIGRATE_FLAG" == "false" ]; then
              ./enable-reindex-cron.sh
              echo "export DESTINATION_TABLE=$(./scripts/dynamo/get-destination-table.sh $ENV)" >> $BASH_ENV
            fi
      - run:
          name: Reindex
          command: |
            if [ "$REINDEX_FLAG" == "true" ] && [ "$MIGRATE_FLAG" == "false" ]; then
              node ./web-api/reindex-dynamodb-records.js "${DESTINATION_TABLE}"
            fi

  migrate:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export MIGRATE_FLAG=$(./scripts/dynamo/get-migrate-flag.sh $ENV)" >> $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
            echo "export DESTINATION_TABLE=$(./scripts/dynamo/get-destination-table.sh $ENV)" >> $BASH_ENV
            echo "export SOURCE_TABLE=$(./scripts/dynamo/get-source-table.sh $ENV)" >> $BASH_ENV
      - run:
          name: Deploy Migration Cron Lambda
          command: |
            npm run deploy:migration-cron -- $ENV
      - run:
          name: Setup Migration Infrastructure
          command: |
            if [ "$MIGRATE_FLAG" == "true" ]; then
              npm run deploy:migration -- $ENV
            fi
      - run:
          name: Disable Destination Table Stream
          command: |
            if [ "$MIGRATE_FLAG" == "true" ]; then
              ./web-api/disable-deploying-dynamo-stream-trigger.sh
            fi
      - run:
          name: Run Migration
          command: |
            if [ "$MIGRATE_FLAG" == "true" ]; then
              npm run start:migration -- $ENV
            fi
      - run:
          name: Wait for SQS Queue to Empty
          no_output_timeout: 5h
          command: |
            if [ "$MIGRATE_FLAG" == "true" ]; then
              ./wait-for-migration-to-finish.sh
            fi
      - run:
          name: Track successful migrations
          command: |
            if [ "$MIGRATE_FLAG" == "true" ]; then
              node ./web-api/track-successful-migrations.js
            fi
      - run:
          name: Enable Destination Table Stream
          command: |
            if [ "$MIGRATE_FLAG" == "true" ]; then
              ./web-api/enable-deploying-dynamo-stream-trigger.sh
            fi
      - run:
          name: Enable Check Reindex Status Cron
          command: |
            ./enable-reindex-cron.sh

  disable-reindex-cron:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
      - run:
          name: Disable Check Reindex Status Cron
          command: |
            ./disable-reindex-cron.sh

  smoketests:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-and-cypress-install
      - run:
          name: Create Cypress Artifacts Directory
          command: mkdir /tmp/cypress
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
      - run:
          name: 'Disable Maintenance Mode'
          command: npm run maintenance:disengage $ENV
      - run:
          name: 'Cypress Smoke Tests'
          command: npm run cypress:smoketests
      - run:
          name: 'Pa11y Smoke Tests'
          command: npm run test:pa11y:smoketests
      - store_artifacts:
          path: /root/project/cypress-smoketests/videos/

  smoketests-readonly:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-and-cypress-install
      - run:
          name: Create Cypress Artifacts Directory
          command: mkdir /tmp/cypress
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
      - run:
          name: Create and Enable Test User
          command: node ./scripts/create-and-enable-smoketest-user.js
      - run:
          name: 'Cypress Readonly Smoke Tests'
          command: |
            set +e
            npm run cypress:readonly
            echo "export READONLY_SMOKETESTS_RESULT=$?" >> $BASH_ENV
            set -e
      - run:
          name: Disable Test User
          command: node ./scripts/disable-smoketest-user.js
      - run:
          name: Kill Build if Smoketests Failed
          command: ./scripts/kill-circle-build.sh
      - run:
          name: 'Cypress Public Readonly Smoke Tests'
          command: npm run cypress:readonly:public
      - store_artifacts:
          path: /root/project/cypress-readonly/videos/

  switch-colors:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: medium+
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export MIGRATE_FLAG=$(./scripts/dynamo/get-migrate-flag.sh $ENV)" >> $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
            echo "export CURRENT_COLOR=$(./scripts/dynamo/get-current-color.sh $ENV)" >> $BASH_ENV
      - run:
          name: 'Switch Colors'
          command: npm run switch-colors

  backup-source-dynamo-table:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: small
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export MIGRATE_FLAG=$(./scripts/dynamo/get-migrate-flag.sh $ENV)" >> $BASH_ENV
            echo "export TABLE_NAME=$(./scripts/dynamo/get-source-table.sh $ENV)" >> $BASH_ENV
      - run:
          name: Backup Source DynamoDB table
          command: |
            if [ $MIGRATE_FLAG == true ]; then
              npm run backup:dynamo-table -- $TABLE_NAME
            fi

  delete-api-mappings:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: small
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export DEPLOYING_COLOR=$(./scripts/dynamo/get-deploying-color.sh $ENV)" >> $BASH_ENV
      - run:
          name: Delete Source API Gateway Mappings
          command: |
            npm run delete:api-gateway-mappings -- "${EFCMS_DOMAIN}" "${DEPLOYING_COLOR}"

  cleanup:
    docker:
      - image: $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/ef-cms-us-east-1:1.6.0
        aws_auth:
          aws_access_key_id: $AWS_ACCESS_KEY_ID
          aws_secret_access_key: $AWS_SECRET_ACCESS_KEY
    resource_class: small
    steps:
      - git-shallow-clone/checkout
      - npm-install
      - run:
          name: Setup Env
          command: |
            cat "./env-for-circle/${CIRCLE_BRANCH}${CONFIG_SUFFIX}.sh" >> $BASH_ENV
            source $BASH_ENV
            echo "export DESTINATION_TABLE=$(./scripts/dynamo/get-destination-table.sh $ENV)" >> $BASH_ENV
            echo "export MIGRATE_FLAG=$(./scripts/dynamo/get-migrate-flag.sh $ENV)" >> $BASH_ENV
            echo "export REINDEX_FLAG=$(./scripts/dynamo/get-reindex-flag.sh $ENV)" >> $BASH_ENV
            echo "export SOURCE_TABLE=$(./scripts/dynamo/get-source-table.sh $ENV)" >> $BASH_ENV
            echo "export SOURCE_ELASTICSEARCH=$(./scripts/elasticsearch/get-source-elasticsearch.sh $ENV)" >> $BASH_ENV
      - run:
          name: Destroy Migration Infrastructure
          command: |
            if [ $MIGRATE_FLAG == true ]; then
              npm run destroy:migration -- $ENV
            fi
      - run:
          name: Destroy Migration Cron Infrastructure
          command: |
            if [ $MIGRATE_FLAG == true ]; then
              npm run destroy:migration-cron -- $ENV
            fi
      - run:
          name: Delete Source ElasticSearch cluster
          command: |
            if [ $MIGRATE_FLAG == true ]; then
              npm run delete:elasticsearch-cluster -- $SOURCE_ELASTICSEARCH
            fi
      - run:
          name: Delete Source Dynamo table
          command: |
            if [ $MIGRATE_FLAG == true ]; then
              npm run delete:dynamo-table -- $SOURCE_TABLE
            fi
      - run:
          name: Cleanup Deploy Table After Migration
          command: |
            if [ $MIGRATE_FLAG == true ]; then
              npm run migration:cleanup -- $ENV
            fi
      - run:
          name: Cleanup Deploy Table After Reindex
          command: |
            if [ $REINDEX_FLAG == true ]; then
              npm run reindex:cleanup -- $ENV
            fi

build-and-deploy-defaults: &build-and-deploy-defaults
  filters:
    branches:
      ignore:
        - prod # run with context workflow below

build-and-deploy-with-context-defaults: &build-and-deploy-with-context-defaults
  context: efcms-<< pipeline.git.branch >>
  filters:
    branches:
      only:
        - prod

workflows:
  version: 2

  build-and-deploy:
    jobs:
      - build-client-integration:
          <<: *build-and-deploy-defaults
      - e2e-pa11y:
          <<: *build-and-deploy-defaults
      - e2e-pa11y-public:
          <<: *build-and-deploy-defaults
      - e2e-pa11y-public-search:
          <<: *build-and-deploy-defaults
      - e2e-cypress:
          <<: *build-and-deploy-defaults
      - e2e-cypress-smoketests-local:
          <<: *build-and-deploy-defaults
      - e2e-cypress-public:
          <<: *build-and-deploy-defaults
      - verify-pdfs:
          <<: *build-and-deploy-defaults
      - deploy:
          requires:
            - build-client-integration
            - e2e-pa11y
            - e2e-pa11y-public
            - e2e-pa11y-public-search
            - e2e-cypress
            - e2e-cypress-smoketests-local
            - e2e-cypress-public
            - verify-pdfs
          filters:
            branches:
              only:
                - develop
                - irs
                - staging
                - test
                - experimental1
                - experimental2
                - experimental3
                - experimental4
                - experimental5
                - migration
      - reindex:
          requires:
            - deploy
      - migrate:
          requires:
            - reindex
          filters:
            branches:
              only:
                - develop
                - irs
                - staging
                - test
                - experimental1
                - experimental2
                - experimental3
                - experimental4
                - experimental5
                - migration
      - wait-for-reindex:
          type: approval
          requires:
            - migrate
      - disable-reindex-cron:
          requires:
            - wait-for-reindex
      - smoketests:
          requires:
            - disable-reindex-cron
          filters:
            branches:
              only:
                - develop
                - irs
                - staging
                - test
                - experimental1
                - experimental2
                - experimental3
                - experimental4
                - experimental5
                - migration
      - smoketests-readonly:
          requires:
            - smoketests
          filters:
            branches:
              only:
                - develop
                - irs
                - staging
                - test
                - experimental1
                - experimental2
                - experimental3
                - experimental4
                - experimental5
                - migration
      - switch-colors:
          requires:
            - smoketests-readonly
          filters:
            branches:
              only:
                - develop
                - irs
                - staging
                - test
                - experimental1
                - experimental2
                - experimental3
                - experimental4
                - experimental5
                - migration
      - cleanup:
          requires:
            - switch-colors
          filters:
            branches:
              only:
                - develop
                - irs
                - staging
                - test
                - experimental1
                - experimental2
                - experimental3
                - experimental4
                - experimental5
                - migration

  build-and-deploy-with-context:
    jobs:
      - build-client-integration:
          <<: *build-and-deploy-with-context-defaults
      - e2e-pa11y:
          <<: *build-and-deploy-with-context-defaults
      - e2e-pa11y-public:
          <<: *build-and-deploy-with-context-defaults
      - e2e-pa11y-public-search:
          <<: *build-and-deploy-with-context-defaults
      - e2e-cypress:
          <<: *build-and-deploy-with-context-defaults
      - e2e-cypress-smoketests-local:
          <<: *build-and-deploy-with-context-defaults
      - e2e-cypress-public:
          <<: *build-and-deploy-with-context-defaults
      - verify-pdfs:
          <<: *build-and-deploy-with-context-defaults
      - deploy:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - build-client-integration
            - e2e-pa11y
            - e2e-pa11y-public
            - e2e-pa11y-public-search
            - e2e-cypress
            - e2e-cypress-smoketests-local
            - e2e-cypress-public
            - verify-pdfs
      - reindex:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - deploy
      - migrate:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - reindex
      - wait-for-reindex:
          <<: *build-and-deploy-with-context-defaults
          type: approval
          requires:
            - migrate
      - disable-reindex-cron:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - wait-for-reindex
      - smoketests-readonly:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - disable-reindex-cron
      - switch-colors:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - smoketests-readonly
      - backup-source-dynamo-table:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - switch-colors
      - delete-api-mappings:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - switch-colors
      - cleanup:
          <<: *build-and-deploy-with-context-defaults
          requires:
            - backup-source-dynamo-table
            - delete-api-mappings
